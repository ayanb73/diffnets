{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In general, before running diffnets your directory structure should look something like this... you have a directory that contains simulation data. In that directory you have a directory for each variant that contains all simulations for that given variant. Then, you should have pdb files to go with the trajectories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "practice_dir\n",
    "|\n",
    "|\n",
    " ----->simulation_data\n",
    "         |----->var1\n",
    "               ------sim1.xtc\n",
    "               ------sim2.xtc\n",
    "               ------sim3.xtc\n",
    "         |----->var2\n",
    "               ------sim1.xtc\n",
    "               ------sim2.xtc\n",
    "               ------sim3.xtc\n",
    "          |var1.pdb\n",
    "          |var2.pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here, copy the diffnets **diffnets/tests/data** to a new directory to practice running diffnets. This dataset only contains two variants and they each have one trajectory so your setup should look something like this:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "practice_dir\n",
    "|\n",
    "|\n",
    " ----->data\n",
    "         |----->var1\n",
    "               ------beta-peptide1.xtc\n",
    "         |----->var2\n",
    "               ------beta-peptide2.xtc\n",
    "         |beta-peptide1.pdb\n",
    "         |beta-peptide2.pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, cd into your practice dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mickdub/bowman_lab/scratch/practice_dir\n"
     ]
    }
   ],
   "source": [
    "cd practice_dir/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, we need to preprocess this simulation data to turn it into DiffNet input\n",
    "-- Ultimately, we want to do that through the command line interface (CLI) which looks like this...\n",
    "\n",
    "**python /path/to/diffnets/diffnets/cli/main.py process {sim_dirs} {pdb_fns} {outdir}**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sim_dirs = np.array([\"./data/var1/\",\n",
    "            \"./data/var2/\"])\n",
    "np.save(\"./traj_dirs.npy\",sim_dirs)\n",
    "\n",
    "pdb_fns = np.array([\"./data/beta-peptide1.pdb\",\n",
    "                    \"./data/beta-peptide2.pdb\"])\n",
    "np.save(\"./pdb_fns.npy\",pdb_fns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to note that the order of **sim_dirs** and **pdb_fns** matters and the pdb order has to correspond to the trajectory order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, our directory looks something like this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "practice_dir\n",
    "  |\n",
    "  |pdb_fns.npy\n",
    "  |traj_dirs.npy\n",
    "  |\n",
    "   ----->data\n",
    "         |----->var1\n",
    "               ------beta-peptide1.xtc\n",
    "         |----->var2\n",
    "               ------beta-peptide2.xtc\n",
    "         |beta-peptide1.pdb\n",
    "         |beta-peptide2.pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are ready to run the data processing step! You should run this next step at the command line (outside of this notebook). Submit this to a CPU node on a cluster and request as many cores as are available on that node.\n",
    "\n",
    "**python /path/to/diffnets/diffnets/cli/main.py process ./traj_dirs.npy ./pdb_fns.npy ./whitened_data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--Optional parameters to add: \n",
    "\n",
    "    -a is an option specify an atom selection. The default will choose the C, CA, CB, and N atoms from both supplied PDB files. However, if your data requires a special atom selection, you must provide a numpy file that is a list of lists where each inner list contains the indices to select from each PDB file that you supplied. If your atom selection file is name \"atom_sel.npy\" then you should add the following to the above python command:\n",
    "    \n",
    "    -aatom_sel.npy (No space between the -a and the file name)\n",
    "    \n",
    "    -s is an option to set the stride for each dataset. This is useful if you have an excess of data (you typically only need tens to hundreds of thousance of simulation frames), OR if your datasets are unbalanced. For example, if var1 has 1 million structures, and var2 has 500,000 structures, you would want to set the stride to something like [10, 5] which will leave you with 100,000 structures from each variant. Save a numpy file called \"stride.npy\" that contains a list of integers where each integer designates the stride for a given variant. The order must follow the order that you supplied the PDBs.\n",
    "    \n",
    "    -sstride.npy (No space between the -s and the file names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, your directory should look something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "practice_dir\n",
    "  |pdb_fns.npy\n",
    "  |traj_dirs.npy\n",
    "  |\n",
    "   ----->data\n",
    "           ----->var1\n",
    "                   |beta-peptide1.xtc\n",
    "           ----->var2\n",
    "                   |beta-peptide2.xtc\n",
    "           |beta-peptide1.pdb\n",
    "           |beta-peptide2.pdb\n",
    "           |\n",
    "   ----->whitened_data\n",
    "           ----->indicators\n",
    "                   |000000.npy\n",
    "                   |000001.npy\n",
    "           ----->data\n",
    "                   |5001 .pt files (one for each simulation frame)\n",
    "           ----->aligned_xtcs\n",
    "                   |000000.xtc\n",
    "                   |000001.xtc\n",
    "           ----->whitened_xtcs\n",
    "           |master.pdb\n",
    "           |traj_dict.pkl\n",
    "           |traj_lens.npy\n",
    "           |cm.npy\n",
    "           |c00.npy\n",
    "           |uwm.npy\n",
    "           |wm.npy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have added a \"whitened_data\" directory that contains the following:\n",
    "\n",
    "--an **aligned_xtcs** dir: one .xtc file for each trajectory where the trajectory has been stripped to (C,CA,CB,N) atoms and aligned to the first pdb supplied in pdb_fns (beta-peptide1.pdb). To change what atom selection you want to use, you can optionally supply {atom_sel} to the CLI command that generated this data. See the preprocess_data function in cli/main.py for more details.\n",
    "\n",
    "--an **indicators** dir: one .npy file for each trajectory where the numbering matches the numbering in aligned_xtcs. The file is a numpy array that has as many values as simulation frames and indicates which variant the trajectory is of. It is zero-indexed so in our case, a value of 0 indicates var1 and a value of 1 indicates var2.\n",
    "\n",
    "--a **data** dir: one .pt file (pytorch tensor) for each simulation frame. Lots of data means lots of files here.\n",
    "\n",
    "--master.pdb: The stripped pdb (C,CA,CB,N) containing the set of atoms that is common to all variants. \n",
    "\n",
    "--traj_dict.pkl: Helper for plotting later (see Analysis.assign_labels_to_variants in analysis.py for more info).\n",
    "\n",
    "--cm.npy: center of mass calculated from ALL simulation frames.\n",
    "\n",
    "--c00.npy: covariance matrix calculated from ALL simulation frames. \n",
    "\n",
    "--wm.npy: whitening matrix which will be used as a layer in the DiffNet.\n",
    "\n",
    "--uwm.npy: unwhitening matrix which will be used as a layer in the DiffNet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here, we will train the diffnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ultimately, we want to run this command:\n",
    "    \n",
    "**python /path/to/diffnets/diffnets/cli/main.py train config.yml**\n",
    "\n",
    "take a look at an example config.yml file at docs/train_sample.yml, but I will also display it here. Pay attention to the comments in the cell below.\n",
    "\n",
    "Remember, we are still cd'd into practice_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir: './whitened_data'\n",
    "n_epochs: 10 #How many times do we want to go through the training data?\n",
    "act_map: [0,1] #initial label for var1 is 0 and for var2 its 1. \n",
    "               #Important note, if we had 4 variants (var1, var2, var3, var4) and we wanted to distingusih\n",
    "               #var1,var2 from var3, var4 act_map would look like [0,0,1,1].\n",
    "               #The order follows the order we originally put in pdb_fns.npy\n",
    "lr: 0.0001\n",
    "n_latent: 50 #Number of dimensions to reduce the data down to.\n",
    "hidden_layer_sizes: [] #Leave blank array [] for default of 1 hidden layer\n",
    "                       #that has 4x less nodes than input.\n",
    "em_bounds: [[0.1,0.4],[0.6,0.9]] #one bound for each variant -- these are reasonable default values\n",
    "do_em: True\n",
    "em_batch_size: 150\n",
    "nntype: 'nnutils.sae' #one of several architectures that can be used, the other\n",
    "                      #common choice would be nnutils.split_sae.\n",
    "                      #nnutils.sae classifies based on the entire protein structure\n",
    "                      #nnutils.split_sae can classify (find differences) based on a specific region\n",
    "                      #of the structure. For nnutils.split_sae you will have to supply indices via the\n",
    "                      #close_inds_fn option described below.\n",
    "batch_size: 32\n",
    "batch_output_freq: 500\n",
    "epoch_output_freq: 2\n",
    "test_batch_size: 1000\n",
    "frac_test: 0.1\n",
    "subsample: 1  #You can subsample the data during training. Recommended if training on huge datasets. \n",
    "outdir: 'sae_e10_lr0001_lat50_rep0_em' #training will create an output directory. Name it however you like\n",
    "                                       #just make sure a dir with the same name doesn't already exist\n",
    "data_in_mem: False  #For small datasets, you can load all the data into memory at once\n",
    "#close_inds_fn: close_inds.npy #Only necessary if using a split autoencoder. np.array of the atom indices that go into classification task. See train_sample.txt.\n",
    "#label_spreading: 'gaussian' #Optional parameter to draw initial labels from a normal distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After making a similar .yml file, run this command **python /path/to/diffnets/diffnets/cli/main.py train config.yml** preferably on a GPU node with CUDA 10.1 installed as discussed in the installation guide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now your directory should look something like this -- for the sake of brevity the contents of the newly added dir are not exactly as you might see them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "practice_dir\n",
    "  |pdb_fns.npy\n",
    "  |traj_dirs.npy\n",
    "  |\n",
    "   ----->data\n",
    "           ----->var1\n",
    "                   |beta-peptide1.xtc\n",
    "           ----->var2\n",
    "                   |beta-peptide2.xtc\n",
    "           |beta-peptide1.pdb\n",
    "           |beta-peptide2.pdb\n",
    "           |\n",
    "   ----->whitened_data\n",
    "           ----->indicators\n",
    "                   |000000.npy\n",
    "                   |000001.npy\n",
    "           ----->data\n",
    "                   |5001 .pt files (one for each simulation frame)\n",
    "           ----->aligned_xtcs\n",
    "                   |000000.xtc\n",
    "                   |000001.xtc\n",
    "           ----->whitened_xtcs\n",
    "           |master.pdb\n",
    "           |traj_dict.pkl\n",
    "           |traj_lens.npy\n",
    "           |cm.npy\n",
    "           |c00.npy\n",
    "           |uwm.npy\n",
    "           |wm.npy\n",
    "   ----->sae_e10_lr0001_lat50_rep0_em\n",
    "           |nn_best_polish.pkl + many other pkl files of intermediate networks saved\n",
    "           |tmp_targets.npy\n",
    "           |training_loss.npy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In your new dir **sae_e10_lr0001_lat50_rep0_em** you have trained diffnets (e.g. nn_best_polish.pkl) and some other data that is not a major concern to explore right now. Just make sure you have nn_best_polish.pkl."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here, we can simply run this command (preferrably on a CPU node with many cores)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**python /path/to/diffnets/diffnets/cli/main.py analyze ./whitened_data ./sae_e10_lr0001_lat50_rep0_em**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, your directory structure will look like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "practice_dir\n",
    "  |pdb_fns.npy\n",
    "  |traj_dirs.npy\n",
    "  |\n",
    "   ----->data\n",
    "           ----->var1\n",
    "                   |beta-peptide1.xtc\n",
    "           ----->var2\n",
    "                   |beta-peptide2.xtc\n",
    "           |beta-peptide1.pdb\n",
    "           |beta-peptide2.pdb\n",
    "           |\n",
    "   ----->whitened_data\n",
    "           ----->indicators\n",
    "                   |000000.npy\n",
    "                   |000001.npy\n",
    "           ----->data\n",
    "                   |5001 .pt files (one for each simulation frame)\n",
    "           ----->aligned_xtcs\n",
    "                   |000000.xtc\n",
    "                   |000001.xtc\n",
    "           ----->whitened_xtcs\n",
    "           |master.pdb\n",
    "           |traj_dict.pkl\n",
    "           |traj_lens.npy\n",
    "           |cm.npy\n",
    "           |c00.npy\n",
    "           |uwm.npy\n",
    "           |wm.npy\n",
    "   ----->sae_e10_lr0001_lat50_rep0_em\n",
    "           ----->encodings\n",
    "                   |000000.npy\n",
    "                   |000001.npy\n",
    "           ----->labels\n",
    "                   |000000.npy\n",
    "                   |000001.npy\n",
    "           ----->recon_trajs\n",
    "                   |000000.xtc\n",
    "                   |000001.xtc\n",
    "           ----->morph_label\n",
    "                   |morph_0-1.pdb\n",
    "           ----->cluster_1000\n",
    "                   |clusters.pkl\n",
    "           |rmsd.npy\n",
    "           |res-corr100.pml\n",
    "           |nn_best_polish.pkl + many other pkl files of intermediate networks saved\n",
    "           |tmp_targets.npy\n",
    "           |training_loss.npy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**recon_trajs**: each trajectory gets reconstructed by the DiffNets and an rmsd to the original trajectories is calculated for every 100th frame (**rmsd.npy**)\n",
    "\n",
    "**labels**: each trajectory has a .npy file where the numpy array contains a DiffNet classification label for each frame\n",
    "\n",
    "**encodings**: each trajectory has a .npy file where the numpy array contains the latent vector for each frame (i.e. your reduced dimensionality representation)\n",
    "\n",
    "**morph_label**: A pdb containing 10 representative states morphing from a DiffNet classification label of 0 to 1\n",
    "\n",
    "**cluster_1000**: A k-centers/k-medoids hybrid clustering using the DiffNet latent space\n",
    "\n",
    "**res-corr100.pml**: Load whitened_data/master.pdb into pymol, then load this pml file in to get an image like Figure 7 in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
